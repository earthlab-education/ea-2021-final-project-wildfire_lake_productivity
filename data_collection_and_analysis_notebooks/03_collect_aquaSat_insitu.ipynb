{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives: \n",
    "    1. Import AquaStat data found on figshare\n",
    "    2. Map data with folium to determine geographic subset\n",
    "    3. Subset data to Southwest or Rockies?  Looking for lakes that might overlap with\n",
    "    MTBS\n",
    "\n",
    "Used with earth-analytics environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages / set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datatools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-929ff254af00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdatatools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datatools'"
     ]
    }
   ],
   "source": [
    "import earthpy as et\n",
    "import os \n",
    "import io\n",
    "import requests\n",
    "import feather\n",
    "import datatools\n",
    "import folium\n",
    "import urllib\n",
    "import json\n",
    "import ee\n",
    "import geemap\n",
    "import numpy as np\n",
    "#from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import warnings\n",
    "#from shapely.geometry import Point\n",
    "\n",
    "# Initialize Google Earth Engine to grab landsat images in section 4\n",
    "#ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "\n",
    "# if the desired path exists:\n",
    "data_dir = os.path.join(et.io.HOME, 'Dropbox', 'cu_earthdata_certificate_2021', 'earthlab_project', 'data')\n",
    "if os.path.exists(data_dir):\n",
    "    # set working directory:\n",
    "    os.chdir(data_dir)\n",
    "    print(\"path exists\")\n",
    "else:\n",
    "    print(\"path does not exist, making new path\")\n",
    "    os.makedirs(data_dir)\n",
    "    os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download the region shapefile \n",
    "to use in clipping the MTBS and HydroLAKES dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = ['Colorado','Utah', 'Wyoming', 'New Mexico', 'Arizona']\n",
    "states = ee.FeatureCollection(\"TIGER/2018/States\").filter(ee.Filter.inList('NAME', lis))\n",
    "\n",
    "states_gdf = geemap.ee_to_geopandas(states, selectors = ['NAME'])\n",
    "print(\"The crs of your area of interest df is\", states_gdf.crs)\n",
    "states_gdf.head()\n",
    "\n",
    "bounding_box = states_gdf.envelope\n",
    "states_bb = gpd.GeoDataFrame(gpd.GeoSeries(bounding_box), columns=['geometry'])\n",
    "states_bb\n",
    "\n",
    "sw_union = states_bb.dissolve() # dissolve states to one poly for maps below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset this dataframe one more time, extracting only data that align with burned lake dataset created\n",
    "# in script 1\n",
    "# This is the dataset that includes the whole 2km 'catchment' of lakes that overlap with mtbs perimeters.\n",
    "# Any data inside of these catchements should be evaluated, not just within the actual overlapping polygon \n",
    "# (e.g. landsat_n_burnpolys.shp) \n",
    "\n",
    "mtbslakes_fp = os.path.join(\"whole_burned_lakes.shp\")\n",
    "mtbslakes = gpd.read_file(mtbslakes_fp).to_crs(epsg=4326)\n",
    "\n",
    "# Bring in burn perimeters \n",
    "mtbs_fp = os.path.join( \"mtbs_polys\", \"mtbs_polys.shp\")\n",
    "fire_perims = gpd.read_file(mtbs_fp).to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Read AquaSat dataset \n",
    "   subset to burned lakes from mtbslakes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in aquaSat .csv and subset to region of interest\n",
    "\n",
    "#https://figshare.com/\n",
    "aquasat_url = 'https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/18733733/sr_wq_rs_join.csv'\n",
    "\n",
    "# Define output file\n",
    "file_path = os.path.join(\"aquasat.csv\")\n",
    "\n",
    "if not os.path.isfile(file_path):    \n",
    "    aquasat = pd.read_csv(aquasat_url, index_col=0)\n",
    "    aquasat.to_csv(output_fp)\n",
    "    # creating a geometry column \n",
    "    geometry = [Point(xy) for xy in zip(aquasat['long'], aquasat['lat'])]\n",
    "    # Creating a Geographic data frame \n",
    "    gdf = gpd.GeoDataFrame(aquasat, crs='epsg:4326', geometry=geometry)\n",
    "    \n",
    "else:\n",
    "    aquasat = pd.read_csv(file_path)\n",
    "    # creating a geometry column \n",
    "    geometry = [Point(xy) for xy in zip(aquasat['long'], aquasat['lat'])]\n",
    "    # Creating a Geographic data frame \n",
    "    gdf = gpd.GeoDataFrame(aquasat, crs='epsg:4326', geometry=geometry)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge aquasat with fire affected lake dataset to retain aquasat points\n",
    "aquasat_burn_points = gpd.overlay(mtbslakes, gdf, how ='intersection', keep_geom_type=False)\n",
    "\n",
    "\n",
    "# merge aquasat with fire affected lake dataset to retain lake catchment polys\n",
    "aquasat_burn_polys = gpd.overlay(mtbslakes, gdf, how ='union', keep_geom_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquasat_burn_polys.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now aquasat_burn is a dataset of burned lakes with chla and some landsat/color data. It does not yet have LimnoSat's dWL data. \n",
    "\n",
    "Export this as a shapefile to use when collecting landscape data in the next notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(\"burned_w_aquasat_points.shp\")\n",
    "aquasat_burn_points.to_file(out_path)\n",
    "\n",
    "\n",
    "out_path = os.path.join(\"burned_w_aquasat_polys.shp\")\n",
    "aquasat_burn_polys.to_file(out_path)\n",
    "aquasat_burn_polys.to_file(\"burned_w_aquasat_polys.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how the data is disbursed\n",
    "# plot subsets\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "sw_union['geometry'].plot(ax=ax, \n",
    "                color = 'brown',\n",
    "                 alpha = 0.5);\n",
    "\n",
    "mtbslakes['geometry'].plot(ax=ax, \n",
    "                color='blue', \n",
    "                alpha=1);\n",
    "\n",
    "\n",
    "aquasat_burn_points['geometry'].plot(ax=ax, \n",
    "                color = 'black',\n",
    "                 alpha = 0.5);\n",
    "\n",
    "ax.set(facecolor = \"grey\")\n",
    "#.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folium' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-75793ecf0840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Stamen Terrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m37\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m105\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Stamen Terrain\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzoom_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgeo_df_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maquasat_burn_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'folium' is not defined"
     ]
    }
   ],
   "source": [
    "# Stamen Terrain\n",
    "map = folium.Map(location = [37,-105], tiles = \"Stamen Terrain\", zoom_start = 5)\n",
    "map\n",
    "\n",
    "geo_df_list = [[point.xy[1][0], point.xy[0][0]] for point in aquasat_burn_points.geometry ]\n",
    "\n",
    "i = 0\n",
    "for coordinates in geo_df_list:\n",
    "    map.add_child(folium.Marker(location = coordinates,\n",
    "                            popup =\n",
    "                            \"Hylak_id: \" + str(aquasat_burn.Hylak_id[i]) + '<br>' +\n",
    "                            \"ChlA: \" + str(aquasat_burn.chl_a[i]) + '<br>' +\n",
    "                            \"Coordinates: \" + str(geo_df_list[i]),\n",
    "                            icon = folium.Icon(color = 'green')))\n",
    "    i = i + 1\n",
    "\n",
    "for _, f in fire_perims.iterrows():\n",
    "    #sim_geo = gpd.GeoSeries(r['geometry'])\n",
    "    sim_geo = gpd.GeoSeries(f['geometry']).simplify(tolerance=0.001)\n",
    "    geo_f = sim_geo.to_json()\n",
    "    geo_f = folium.GeoJson(data=geo_f,\n",
    "                           style_function=lambda x: {'fillColor': 'orange', 'color': 'orange'})\n",
    "    geo_f.add_child(folium.Popup(f['Incid_Name']))\n",
    "    #folium.Popup(r['Incid_Name']).add_to(geo_j)\n",
    "    geo_f.add_to(map)\n",
    "    \n",
    "for _, r in mtbslakes.iterrows():\n",
    "    #without simplifying the representation of each borough, the map might not be displayed\n",
    "    #sim_geo = gpd.GeoSeries(r['geometry'])\n",
    "    sim_geo = gpd.GeoSeries(r['geometry']).simplify(tolerance=0.001)\n",
    "    geo_j = sim_geo.to_json()\n",
    "    geo_j = folium.GeoJson(data=geo_j,\n",
    "                           style_function=lambda x: {'fillColor': 'blue'})\n",
    "    #folium.Popup(r['Hylak_id']).add_to(geo_j)\n",
    "    geo_j.add_child(folium.Popup(r['Hylak_id']))\n",
    "    geo_j.add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in mtbs data (whole_burned_lakes is HydroLakes and LimnoSat data)\n",
    "in_path = os.path.join(\"landsat_n_burnpolys.shp\")\n",
    "landsat_n_burnpolys = gpd.read_file(in_path, bbox=sw_union).to_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure Hylak_id is an integer to match aquasat_burn\n",
    "# merge aquasat with fire affected lake dataset\n",
    "aquasat_burn_landsat = gpd.overlay(aquasat_burn_points, landsat_n_burnpolys,  how ='union', keep_geom_type= 'TRUE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both aquasat_burn and landsat_n_burnpolys contain the Hylak_id unique identifier.\n",
    "Merge these datasets based on Hylak_id (subsetting landsat-n-burnpolys to those with \n",
    "insitu data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how the data is disbursed\n",
    "# plot subsets\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "sw_union['geometry'].plot(ax=ax, \n",
    "                color = 'palegoldenrod',\n",
    "                 alpha = 0.5);\n",
    "\n",
    "aquasat_burn['geometry'].plot(ax=ax, \n",
    "                color = 'black',\n",
    "                 alpha = 1);\n",
    "\n",
    "# landsat_n_burnpolys['geometry'].plot(ax=ax, \n",
    "#                 color='white', \n",
    "#                 alpha=.25);\n",
    "\n",
    "\n",
    "# aquasat_burn_landsat['geometry'].plot(ax=ax, \n",
    "#                 color='pink', \n",
    "#                 alpha=.50);\n",
    "\n",
    "ax.set(facecolor = \"grey\")\n",
    "#.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pre or post fire classification of Landsat imagery based on condition\n",
    "# that image date is before ingition date\n",
    "\n",
    "# Convert objects to dates\n",
    "#aquasat_burn_landsat['date_unity'] = aquasat_burn_landsat['date_unity'].strftime(\"%B %d, %Y\")\n",
    "aquasat_burn_landsat['date_unity'] = pd.to_datetime(aquasat_burn_landsat['date_unity']).dt.tz_localize(None)\n",
    "aquasat_burn_landsat['Ig_Date'] = pd.to_datetime(aquasat_burn_landsat['Ig_Date'])\n",
    "aquasat_burn_landsat.date_unity\n",
    "#aquasat_burn_landsat.Ig_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquasat_burn_landsat['pre_post'] = np.where(\n",
    "    aquasat_burn_landsat['date_unity'] < aquasat_burn_landsat['Ig_Date'], \"pre-fire\", \"post-fire\")\n",
    "# print(colo_tabular.pre_post)\n",
    "\n",
    "# Generate a calculation for the lapse of time pre- or post fire for plotting\n",
    "aquasat_burn_landsat['days_since'] = (aquasat_burn_landsat['date_unity'] - aquasat_burn_landsat['Ig_Date'])\n",
    "\n",
    "# Convert days_since to numerical/integer value that can be plotted\n",
    "aquasat_burn_landsat.days_since = aquasat_burn_landsat.days_since.astype(\n",
    "    'timedelta64[D]').astype(int)\n",
    "# print(aquasat_burn_landsatinsitu_burned_lakes.days_since)\n",
    "\n",
    "# Add a image month column for trend monitoring\n",
    "aquasat_burn_landsat['img_month'] = pd.DatetimeIndex(aquasat_burn_landsat['date_unity']).month\n",
    "\n",
    "# Add a classification that identifies the number of years since the fire.\n",
    "# This method allows for manual adjustment of year assingment\n",
    "col = aquasat_burn_landsat['days_since']\n",
    "conditions = [(col < 2920) & (col >= 2555),\n",
    "              (col < 2555) & (col >= 2190),\n",
    "              (col < 2190) & (col >= 1825),\n",
    "              (col < 1825) & (col >= 1460),\n",
    "              (col < 1460) & (col >= 1095),\n",
    "              (col < 1095) & (col >= 730),\n",
    "              (col < 730) & (col >= 365),\n",
    "              (col >= 0) & (col < 365),\n",
    "              (col < 0) & (col >= -365),\n",
    "              (col < -365) & (col >= -730),\n",
    "              (col < -703) & (col >= -1095),\n",
    "              (col < -1095) & (col >= -1460),\n",
    "              (col < -1460) & (col >= -1825),\n",
    "              (col < -1825) | (col >= -2190),\n",
    "              (col < -2190) | (col >= -2555),\n",
    "              (col < -2555) | (col >= -2920)]\n",
    "choices = ['8', '7', '6', '5', '4', '3', '2', '1',\n",
    "           '0', '-1', '-2', '-3', '-4', '-5', '-6', '-7']\n",
    "aquasat_burn_landsat['years_since'] = np.select(conditions, choices, default='meh')\n",
    "aquasat_burn_landsat['years_since'] = aquasat_burn_landsat['years_since'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = aquasat_burn_landsatinsitu_burned_lakes['dWL']\n",
    "conditions = [(col == 583) & (col > 581),\n",
    "              (col <= 581) & (col > 579),\n",
    "              (col <= 579) & (col > 577),\n",
    "              (col <= 577) & (col > 575),\n",
    "              (col <= 575) & (col > 573),\n",
    "              (col <= 573) & (col > 571),\n",
    "              (col <= 571) & (col > 570),\n",
    "              (col <= 570) & (col > 569),\n",
    "              (col <= 569) & (col > 568),\n",
    "              (col <= 568) & (col > 567),\n",
    "              (col <= 567) & (col > 564),\n",
    "              (col <= 564) & (col > 559),\n",
    "              (col <= 559) & (col > 549),\n",
    "              (col <= 549) & (col > 530),\n",
    "              (col <= 530) & (col > 509),\n",
    "              (col <= 509) & (col > 495),\n",
    "              (col <= 495) & (col > 489),\n",
    "              (col <= 489) & (col > 485),\n",
    "              (col <= 485) & (col > 480),\n",
    "              (col <= 480) & (col > 475),\n",
    "              (col > 470) & (col <= 475)]\n",
    "\n",
    "\n",
    "choices = ['21', '20', '19', '18', '17', '16', '15', '14', '13', '12', '11',\n",
    "           '10', '9', '8', '7', '6', '5', '4', '3', '2', '1']\n",
    "aquasat_burn_landsat['fui'] = np.select(conditions, choices, default='1001')\n",
    "aquasat_burn_landsat['fui'] = pd.to_numeric(aquasat_burn_landsat['fui'], errors='coerce')\n",
    "\n",
    "choices = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k',\n",
    "           'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u']\n",
    "aquasat_burn_landsat['fui_color'] = np.select(conditions, choices, default='v')\n",
    "\n",
    "# Check that new or converted values make sense\n",
    "aquasat_burn_landsatinsitu_burned_lakes[['Ig_Date', 'pre_post',\n",
    "              'days_since', 'img_month', 'years_since', 'dWL', 'fui']].head\n",
    "\n",
    "# colo_tabular.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquasat_burn_landsat.Incid_Name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export \n",
    "# Export file to local drive\n",
    "out_path = os.path.join(\"burned_lakes_color_and_insitu.csv\")\n",
    "aquasat_burn_landsat.to_csv(out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plots\n",
    "Looking at pre and post fire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset = iaquasat_burn_landsat.loc[(aquasat_burn_landsat['fui'] != 1001)]\n",
    "\n",
    "# Plot 1\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12, 12))\n",
    "\n",
    "ax1.scatter(x=plot_subset['days_since'],\n",
    "            y=plot_subset['chl_a'],\n",
    "            color='green')\n",
    "ax1.set(title='chl_a in response to time since fire',\n",
    "       xlabel='Days since fire ignition',\n",
    "       ylabel='chl_a')\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "\n",
    "\n",
    "# Plot 2\n",
    "ax2.scatter(x=plot_subset['days_since'],\n",
    "            y=plot_subset['tss'],\n",
    "            color='brown')\n",
    "ax2.set(title='TSS in response to time since fire',\n",
    "       xlabel='Days since fire ignition',\n",
    "       ylabel='Total suspended solids')\n",
    "\n",
    "# Plot 3\n",
    "ax3.scatter(x=plot_subset['days_since'],\n",
    "            y=plot_subset['doc'],\n",
    "            color='purple')\n",
    "ax3.set(title='DOC in response to time since fire',\n",
    "       xlabel='Days since fire ignition',\n",
    "       ylabel='DOC')\n",
    "\n",
    "\n",
    "# Plot 4\n",
    "ax4.scatter(x=plot_subset['days_since'],\n",
    "            y=plot_subset['secchi'],\n",
    "            color='gray')\n",
    "ax4.set(title='Secchi depth in response to time since fire',\n",
    "       xlabel='Days since fire ignition',\n",
    "       ylabel='Secchi depth')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
